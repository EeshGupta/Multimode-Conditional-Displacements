{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68259c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bdf075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 12s 0us/step\n",
      "170508288/170498071 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_img_train, y_label_train), (x_img_test, y_label_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ad8068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_img_train: (50000, 32, 32, 3)\n",
      "y_label_train: (50000, 1)\n",
      "x_img_test: (10000, 32, 32, 3)\n",
      "y_label_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_img_train:', x_img_train.shape)\n",
    "print('y_label_train:', y_label_train.shape)\n",
    "print('x_img_test:', x_img_test.shape)\n",
    "print('y_label_test:', y_label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b790226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HDF5 file\n",
    "with h5py.File('dataset_cifar10.hdf5', 'w') as hf:\n",
    "    dset_x_train = hf.create_dataset('x_train', data=x_img_train, shape=(50000, 32, 32, 3), compression='gzip', chunks=True)\n",
    "    dset_y_train = hf.create_dataset('y_train', data=y_label_train, shape=(50000, 1), compression='gzip', chunks=True)\n",
    "    dset_x_test = hf.create_dataset('x_test', data=x_img_test, shape=(10000, 32, 32, 3), compression='gzip', chunks=True)\n",
    "    dset_y_test = hf.create_dataset('y_test', data=y_label_test, shape=(10000, 1), compression='gzip', chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a8ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"x_train\": shape (50000, 32, 32, 3), type \"|u1\">\n",
      "<HDF5 dataset \"y_train\": shape (50000, 1), type \"|u1\">\n",
      "<HDF5 dataset \"x_test\": shape (10000, 32, 32, 3), type \"|u1\">\n",
      "<HDF5 dataset \"y_test\": shape (10000, 1), type \"|u1\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('dataset_cifar10.hdf5', 'r') as hf:\n",
    "    dset_x_train = hf['x_train']\n",
    "    dset_y_train = hf['y_train']\n",
    "    dset_x_test = hf['x_test']\n",
    "    dset_y_test = hf['y_test']\n",
    "    \n",
    "    print(dset_x_train)\n",
    "    print(dset_y_train)\n",
    "    print(dset_x_test)\n",
    "    print(dset_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0921917",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('dataset_cifar10.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef6f1991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(hf['x_train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda51282",
   "metadata": {},
   "source": [
    "# New H5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e10705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]\n",
    "b = [[2], [3], [4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20731c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('test2.hdf5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adfbe6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = hf.create_dataset('a', data = a, shape = np.shape(a),compression=\"gzip\", chunks=True, maxshape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12a0c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ = hf.create_dataset('b', data = b, shape = np.shape(b), compression=\"gzip\", chunks=True, maxshape=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03988cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_append = h5py.File('test2.hdf5', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a62272ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"test2.hdf5\" (mode r+)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863358a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a = np.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "202539cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_append[\"a\"].resize((hf[\"a\"].shape[0] + new_a.shape[0]), axis = 0)\n",
    "hf_append[\"a\"][-new_a.shape[0]:] = new_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77f7062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_append[\"a\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7681a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " def append_data( f, key, data):\n",
    "        \"\"\"\n",
    "        the main difference between append_pt and append is thta\n",
    "        append takes care of highier dimensional data, but not append_pt\n",
    "        \"\"\"\n",
    "        #EG: fixing this because current config produces the following error: \n",
    "        \n",
    "        f[key].resize((f[key].shape[0] + data.shape[0]), axis = 0)\n",
    "        f[key][-data.shape[0]:] = data\n",
    "        \n",
    "\n",
    "#         data = np.array(data)\n",
    "#         try:\n",
    "#             f.create_dataset(key, shape=tuple([1] + list(data.shape)),\n",
    "#                              maxshape=tuple([None] * (len(data.shape) + 1)),\n",
    "#                              dtype=str(data.dtype))\n",
    "#         except RuntimeError:\n",
    "#             if forceInit == True:\n",
    "#                 del f[key]\n",
    "#                 f.create_dataset(key, shape=tuple([1] + list(data.shape)),\n",
    "#                                  maxshape=tuple(\n",
    "#                                      [None] * (len(data.shape) + 1)),\n",
    "#                                  dtype=str(data.dtype))\n",
    "#             dataset = f[key]\n",
    "#             Shape = list(dataset.shape)\n",
    "#             Shape[0] = Shape[0] + 1\n",
    "#             dataset.resize(Shape)\n",
    "\n",
    "#         dataset = f[key]\n",
    "#         try:\n",
    "#             dataset[-1, :] = data\n",
    "#         except TypeError:\n",
    "#             dataset[-1] = data\n",
    "#             # Usage require strictly same dimensionality for all data appended.\n",
    "#             # currently I don't have it setup to return a good exception, but should\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1150fc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"b\": shape (3, 1), type \"<i4\">"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_append[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f0d2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_b = np.array([[5]])\n",
    "append_data(hf_append, \"b\", new_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87d2ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "720bad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"b\": shape (4, 1), type \"<i4\">"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_append['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ed96cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_append['b'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa732031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
