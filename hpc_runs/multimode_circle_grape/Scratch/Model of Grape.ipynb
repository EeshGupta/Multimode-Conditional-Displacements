{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf351396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorflowState:\n",
    "\n",
    "    def __init__(self, sys_para):\n",
    "\n",
    "        self.sys_para = sys_para\n",
    "\n",
    "    def init_defined_functions(self):\n",
    "        # define propagation functions used for evolution\n",
    "        input_num = len(self.sys_para.Hnames) + 1\n",
    "        taylor_terms = self.sys_para.exp_terms\n",
    "        scaling = self.sys_para.scaling\n",
    "\n",
    "        def get_matexp(uks, H_all):\n",
    "            # matrix exponential\n",
    "            I = H_all[input_num]\n",
    "            matexp = I\n",
    "            uks_Hk_list = []\n",
    "            for ii in range(input_num):\n",
    "                uks_Hk_list.append((uks[ii]/(2.**scaling))*H_all[ii])\n",
    "\n",
    "            H = tf.add_n(uks_Hk_list)\n",
    "            H_n = H\n",
    "            factorial = 1.\n",
    "\n",
    "            for ii in range(1, taylor_terms+1):\n",
    "                factorial = factorial * ii\n",
    "                matexp = matexp + H_n/factorial\n",
    "                if not ii == (taylor_terms):\n",
    "                    H_n = tf.matmul(\n",
    "                        H, H_n, a_is_sparse=self.sys_para.sparse_H, b_is_sparse=self.sys_para.sparse_U)\n",
    "\n",
    "            for ii in range(scaling):\n",
    "                matexp = tf.matmul(\n",
    "                    matexp, matexp, a_is_sparse=self.sys_para.sparse_U, b_is_sparse=self.sys_para.sparse_U)\n",
    "\n",
    "            return matexp\n",
    "\n",
    "        @function.Defun(tf.float32, tf.float32, tf.float32)\n",
    "        def matexp_op_grad(uks, H_all, grad):\n",
    "            # gradient of matrix exponential\n",
    "            coeff_grad = []\n",
    "\n",
    "            coeff_grad.append(tf.constant(0, dtype=tf.float32))\n",
    "\n",
    "            # get output of the function\n",
    "            matexp = get_matexp(uks, H_all)\n",
    "            ###\n",
    "\n",
    "            for ii in range(1, input_num):\n",
    "                coeff_grad.append(tf.reduce_sum(tf.multiply(grad,\n",
    "                                                            tf.matmul(H_all[ii], matexp, a_is_sparse=self.sys_para.sparse_H, b_is_sparse=self.sys_para.sparse_U))))\n",
    "\n",
    "            return [tf.stack(coeff_grad), tf.zeros(tf.shape(H_all), dtype=tf.float32)]\n",
    "\n",
    "        global matexp_op\n",
    "\n",
    "        @function.Defun(tf.float32, tf.float32, grad_func=matexp_op_grad)\n",
    "        def matexp_op(uks, H_all):\n",
    "            # matrix exponential defun operator\n",
    "            matexp = get_matexp(uks, H_all)\n",
    "\n",
    "            return matexp\n",
    "\n",
    "        def get_matvecexp(uks, H_all, psi):\n",
    "            # matrix vector exponential\n",
    "            I = H_all[input_num]\n",
    "            matvecexp = psi\n",
    "\n",
    "            uks_Hk_list = []\n",
    "\n",
    "            for ii in range(input_num):\n",
    "                uks_Hk_list.append(uks[ii]*H_all[ii])\n",
    "\n",
    "            H = tf.add_n(uks_Hk_list)\n",
    "\n",
    "            psi_n = psi\n",
    "            factorial = 1.\n",
    "\n",
    "            for ii in range(1, taylor_terms):\n",
    "                factorial = factorial * ii\n",
    "                psi_n = tf.matmul(\n",
    "                    H, psi_n, a_is_sparse=self.sys_para.sparse_H, b_is_sparse=self.sys_para.sparse_K)\n",
    "                matvecexp = matvecexp + psi_n/factorial\n",
    "\n",
    "            return matvecexp\n",
    "\n",
    "        @function.Defun(tf.float32, tf.float32, tf.float32, tf.float32)\n",
    "        def matvecexp_op_grad(uks, H_all, psi, grad):\n",
    "            # graident of matrix vector exponential\n",
    "            coeff_grad = []\n",
    "\n",
    "            coeff_grad.append(tf.constant(0, dtype=tf.float32))\n",
    "\n",
    "            # get output of the function\n",
    "            matvecexp = get_matvecexp(uks, H_all, psi)\n",
    "            #####\n",
    "\n",
    "            for ii in range(1, input_num):\n",
    "                coeff_grad.append(tf.reduce_sum(tf.multiply(grad,\n",
    "                                                            tf.matmul(H_all[ii], matvecexp, a_is_sparse=self.sys_para.sparse_H, b_is_sparse=self.sys_para.sparse_K))))\n",
    "\n",
    "            I = H_all[input_num]\n",
    "            vec_grad = grad\n",
    "            uks_Hk_list = []\n",
    "            for ii in range(input_num):\n",
    "                uks_Hk_list.append((-uks[ii])*H_all[ii])\n",
    "\n",
    "            H = tf.add_n(uks_Hk_list)\n",
    "            vec_grad_n = grad\n",
    "            factorial = 1.\n",
    "\n",
    "            for ii in range(1, taylor_terms):\n",
    "                factorial = factorial * ii\n",
    "                vec_grad_n = tf.matmul(\n",
    "                    H, vec_grad_n, a_is_sparse=self.sys_para.sparse_H, b_is_sparse=self.sys_para.sparse_K)\n",
    "                vec_grad = vec_grad + vec_grad_n/factorial\n",
    "\n",
    "            return [tf.stack(coeff_grad), tf.zeros(tf.shape(H_all), dtype=tf.float32), vec_grad]\n",
    "\n",
    "        global matvecexp_op\n",
    "\n",
    "        @function.Defun(tf.float32, tf.float32, tf.float32, grad_func=matvecexp_op_grad)\n",
    "        def matvecexp_op(uks, H_all, psi):\n",
    "            # matrix vector exponential defun operator\n",
    "            matvecexp = get_matvecexp(uks, H_all, psi)\n",
    "\n",
    "            return matvecexp\n",
    "\n",
    "    def init_variables(self):\n",
    "        self.tf_one_minus_gaussian_envelope = tf.constant(\n",
    "            self.sys_para.one_minus_gauss, dtype=tf.float32, name='Gaussian')\n",
    "\n",
    "    def init_tf_vectors(self):\n",
    "\n",
    "        self.tf_initial_vectors = []\n",
    "        for initial_vector in self.sys_para.initial_vectors:\n",
    "            tf_initial_vector = tf.constant(initial_vector, dtype=tf.float32)\n",
    "            self.tf_initial_vectors.append(tf_initial_vector)\n",
    "        self.packed_initial_vectors = tf.transpose(\n",
    "            tf.stack(self.tf_initial_vectors))\n",
    "\n",
    "    def init_tf_propagators(self):\n",
    "        # tf initial and target propagator\n",
    "        if self.sys_para.state_transfer:\n",
    "            self.target_vecs = tf.transpose(tf.constant(\n",
    "                np.array(self.sys_para.target_vectors), dtype=tf.float32))\n",
    "        else:\n",
    "            self.tf_initial_unitary = tf.constant(\n",
    "                self.sys_para.initial_unitary, dtype=tf.float32, name='U0')\n",
    "            self.tf_target_state = tf.constant(\n",
    "                self.sys_para.target_unitary, dtype=tf.float32)\n",
    "            self.target_vecs = tf.matmul(\n",
    "                self.tf_target_state, self.packed_initial_vectors)\n",
    "        print(\"Propagators initialized.\")\n",
    "\n",
    "    def init_tf_ops_weight(self):\n",
    "\n",
    "        # tf weights of operators\n",
    "\n",
    "        # Just a vector of ones needed for the kernel\n",
    "        self.H0_weight = tf.Variable(\n",
    "            tf.ones([self.sys_para.steps]), trainable=False)\n",
    "        # will collect all weights here\n",
    "        self.weights_unpacked = [self.H0_weight]\n",
    "        self.ops_weight_base = tf.Variable(tf.constant(\n",
    "            self.sys_para.ops_weight_base, dtype=tf.float32), dtype=tf.float32, name=\"weights_base\")\n",
    "\n",
    "        self.ops_weight = tf.sin(self.ops_weight_base, name=\"weights\")\n",
    "        for ii in range(self.sys_para.ops_len):\n",
    "            self.weights_unpacked.append(\n",
    "                self.sys_para.ops_max_amp[ii]*self.ops_weight[ii, :])\n",
    "\n",
    "        # print len(self.sys_para.ops_max_amp)\n",
    "        self.H_weights = tf.stack(self.weights_unpacked, name=\"packed_weights\")\n",
    "\n",
    "        print(\"Operators weight initialized.\")\n",
    "\n",
    "    def init_tf_inter_propagators(self):\n",
    "        # initialize intermediate unitaries\n",
    "        self.inter_states = []\n",
    "        for ii in range(self.sys_para.steps):\n",
    "            self.inter_states.append(tf.zeros([2*self.sys_para.state_num, 2*self.sys_para.state_num],\n",
    "                                              dtype=tf.float32, name=\"inter_state_\"+str(ii)))\n",
    "        print(\"Intermediate propagation variables initialized.\")\n",
    "\n",
    "    def get_inter_state_op(self, layer):\n",
    "        # build operator for intermediate state propagation\n",
    "        # This function determines the nature of propagation\n",
    "\n",
    "        propagator = matexp_op(self.H_weights[:, layer], self.tf_matrix_list)\n",
    "\n",
    "        return propagator\n",
    "\n",
    "    def init_tf_propagator(self):\n",
    "        self.tf_matrix_list = tf.constant(\n",
    "            self.sys_para.matrix_list, dtype=tf.float32)\n",
    "\n",
    "        # build propagator for all the intermediate states\n",
    "\n",
    "        tf_inter_state_op = []\n",
    "        for ii in np.arange(0, self.sys_para.steps):\n",
    "            tf_inter_state_op.append(self.get_inter_state_op(ii))\n",
    "\n",
    "        # first intermediate propagator\n",
    "        self.inter_states[0] = tf.matmul(tf_inter_state_op[0], self.tf_initial_unitary, a_is_sparse=self.sys_para.sparse_U,\n",
    "                                         b_is_sparse=self.sys_para.sparse_K)\n",
    "        # subsequent operation layers and intermediate propagators\n",
    "\n",
    "        for ii in np.arange(1, self.sys_para.steps):\n",
    "            self.inter_states[ii] = tf.matmul(tf_inter_state_op[ii], self.inter_states[ii-1], a_is_sparse=self.sys_para.sparse_U,\n",
    "                                              b_is_sparse=self.sys_para.sparse_K)\n",
    "\n",
    "        self.final_state = self.inter_states[self.sys_para.steps-1]\n",
    "\n",
    "        self.unitary_scale = (0.5/self.sys_para.state_num)*tf.reduce_sum(\n",
    "            tf.matmul(tf.transpose(self.final_state), self.final_state))\n",
    "\n",
    "        print(\"Intermediate propagators initialized.\")\n",
    "\n",
    "    def init_tf_inter_vectors(self):\n",
    "        # inter vectors for unitary evolution, obtained by multiplying the propagation operator K_j with initial vector\n",
    "        self.inter_vecs_list = []\n",
    "\n",
    "        inter_vec = self.packed_initial_vectors\n",
    "        self.inter_vecs_list.append(inter_vec)\n",
    "\n",
    "        for ii in np.arange(0, self.sys_para.steps):\n",
    "            inter_vec = tf.matmul(\n",
    "                self.inter_states[ii], self.packed_initial_vectors, name=\"inter_vec_\"+str(ii))\n",
    "            self.inter_vecs_list.append(inter_vec)\n",
    "        self.inter_vecs_packed = tf.stack(self.inter_vecs_list, axis=1)\n",
    "        self.inter_vecs = tf.unstack(self.inter_vecs_packed, axis=2)\n",
    "\n",
    "        print(\"Vectors initialized.\")\n",
    "\n",
    "    def init_tf_inter_vector_state(self):\n",
    "        # inter vectors for state transfer, obtained by evolving the initial vector\n",
    "\n",
    "        tf_matrix_list = tf.constant(\n",
    "            self.sys_para.matrix_list, dtype=tf.float32)\n",
    "\n",
    "        self.inter_vecs_list = []\n",
    "        inter_vec = self.packed_initial_vectors\n",
    "        self.inter_vecs_list.append(inter_vec)\n",
    "\n",
    "        for ii in np.arange(0, self.sys_para.steps):\n",
    "            psi = inter_vec\n",
    "            inter_vec = matvecexp_op(\n",
    "                self.H_weights[:, ii], tf_matrix_list, psi)\n",
    "            self.inter_vecs_list.append(inter_vec)\n",
    "        self.inter_vecs_packed = tf.stack(self.inter_vecs_list, axis=1)\n",
    "        self.inter_vecs = tf.unstack(self.inter_vecs_packed, axis=2)\n",
    "\n",
    "        print(\"Vectors initialized.\")\n",
    "\n",
    "    def get_inner_product(self, psi1, psi2):\n",
    "        # Take 2 states psi1,psi2, calculate their overlap, for single vector\n",
    "        state_num = self.sys_para.state_num\n",
    "\n",
    "        psi_1_real = (psi1[0:state_num])\n",
    "        psi_1_imag = (psi1[state_num:2*state_num])\n",
    "        psi_2_real = (psi2[0:state_num])\n",
    "        psi_2_imag = (psi2[state_num:2*state_num])\n",
    "        # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "        with tf.name_scope('inner_product'):\n",
    "            ac = tf.multiply(psi_1_real, psi_2_real)\n",
    "            bd = tf.multiply(psi_1_imag, psi_2_imag)\n",
    "            bc = tf.multiply(psi_1_imag, psi_2_real)\n",
    "            ad = tf.multiply(psi_1_real, psi_2_imag)\n",
    "            reals = tf.square(tf.add(tf.reduce_sum(ac), tf.reduce_sum(bd)))\n",
    "            imags = tf.square(tf.subtract(\n",
    "                tf.reduce_sum(bc), tf.reduce_sum(ad)))\n",
    "            norm = tf.add(reals, imags)\n",
    "        return norm\n",
    "\n",
    "    def get_inner_product_2D(self, psi1, psi2):\n",
    "        # Take 2 states psi1,psi2, calculate their overlap, for arbitrary number of vectors\n",
    "        # psi1 and psi2 are shaped as (2*state_num, number of vectors)\n",
    "        state_num = self.sys_para.state_num\n",
    "\n",
    "        psi_1_real = (psi1[0:state_num, :])\n",
    "        psi_1_imag = (psi1[state_num:2*state_num, :])\n",
    "        psi_2_real = (psi2[0:state_num, :])\n",
    "        psi_2_imag = (psi2[state_num:2*state_num, :])\n",
    "        # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "        with tf.name_scope('inner_product'):\n",
    "            ac = tf.reduce_sum(tf.multiply(psi_1_real, psi_2_real), 0)\n",
    "            bd = tf.reduce_sum(tf.multiply(psi_1_imag, psi_2_imag), 0)\n",
    "            bc = tf.reduce_sum(tf.multiply(psi_1_imag, psi_2_real), 0)\n",
    "            ad = tf.reduce_sum(tf.multiply(psi_1_real, psi_2_imag), 0)\n",
    "            # first trace inner product of all vectors, then squared\n",
    "            reals = tf.square(tf.reduce_sum(tf.add(ac, bd)))\n",
    "            imags = tf.square(tf.reduce_sum(tf.subtract(bc, ad)))\n",
    "            norm = (tf.add(reals, imags)) / \\\n",
    "                (len(self.sys_para.states_concerned_list)**2)\n",
    "        return norm\n",
    "\n",
    "    def get_inner_product_3D(self, psi1, psi2):\n",
    "        # Take 2 states psi1,psi2, calculate their overlap, for arbitrary number of vectors and timesteps\n",
    "        # psi1 and psi2 are shaped as (2*state_num, time_steps, number of vectors)\n",
    "        state_num = self.sys_para.state_num\n",
    "\n",
    "        psi_1_real = (psi1[0:state_num, :])\n",
    "        psi_1_imag = (psi1[state_num:2*state_num, :])\n",
    "        psi_2_real = (psi2[0:state_num, :])\n",
    "        psi_2_imag = (psi2[state_num:2*state_num, :])\n",
    "        # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "        with tf.name_scope('inner_product'):\n",
    "            ac = tf.reduce_sum(tf.multiply(psi_1_real, psi_2_real), 0)\n",
    "            bd = tf.reduce_sum(tf.multiply(psi_1_imag, psi_2_imag), 0)\n",
    "            bc = tf.reduce_sum(tf.multiply(psi_1_imag, psi_2_real), 0)\n",
    "            ad = tf.reduce_sum(tf.multiply(psi_1_real, psi_2_imag), 0)\n",
    "            reals = tf.reduce_sum(tf.square(tf.reduce_sum(tf.add(ac, bd), 1)))\n",
    "            # first trace inner product of all vectors, then squared, then sum contribution of all time steps\n",
    "            imags = tf.reduce_sum(\n",
    "                tf.square(tf.reduce_sum(tf.subtract(bc, ad), 1)))\n",
    "            norm = (tf.add(reals, imags)) / \\\n",
    "                (len(self.sys_para.states_concerned_list)**2)\n",
    "        return norm\n",
    "\n",
    "    def init_training_loss(self):\n",
    "        \n",
    "        self.loss = tf.constant(0.0, dtype=tf.float32)\n",
    "        self.final_state = self.inter_vecs_packed[:,\n",
    "                                                  self.sys_para.steps, :]\n",
    "        self.loss = 1 - \\\n",
    "            self.get_inner_product_2D(self.final_state, self.target_vecs)\n",
    "        self.unitary_scale = self.get_inner_product_2D(\n",
    "            self.final_state, self.final_state)\n",
    "\n",
    "        self.reg_loss = get_reg_loss(self)\n",
    "\n",
    "        print(\"Training loss initialized.\")\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        # Optimizer. Takes a variable learning rate.\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "\n",
    "        # Here we extract the gradients of the pulses\n",
    "        self.grad = self.opt.compute_gradients(self.reg_loss)\n",
    "\n",
    "        self.grad_pack = tf.stack([g for g, _ in self.grad])\n",
    "\n",
    "        self.grads = [tf.nn.l2_loss(g) for g, _ in self.grad]\n",
    "        self.grad_squared = tf.reduce_sum(tf.stack(self.grads))\n",
    "        self.optimizer = self.opt.apply_gradients(self.grad)\n",
    "\n",
    "        print(\"Optimizer initialized.\")\n",
    "\n",
    "    def init_utilities(self):\n",
    "        # Add ops to save and restore all the variables.\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        print(\"Utilities initialized.\")\n",
    "\n",
    "    def build_graph(self):\n",
    "        # graph building for the quantum optimal control\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "\n",
    "            print(\"Building graph:\")\n",
    "\n",
    "            self.init_defined_functions()\n",
    "            self.init_variables()\n",
    "            self.init_tf_vectors()\n",
    "            self.init_tf_propagators()\n",
    "            self.init_tf_ops_weight()\n",
    "            if self.sys_para.state_transfer == False:\n",
    "                self.init_tf_inter_propagators()\n",
    "                self.init_tf_propagator()\n",
    "                if self.sys_para.use_inter_vecs:\n",
    "                    self.init_tf_inter_vectors()\n",
    "                else:\n",
    "                    self.inter_vecs = None\n",
    "            else:\n",
    "                self.init_tf_inter_vector_state()\n",
    "            self.init_training_loss()\n",
    "            self.init_optimizer()\n",
    "            self.init_utilities()\n",
    "\n",
    "            print(\"Graph built!\")\n",
    "\n",
    "        return graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
